{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harakunivj/demoproject/blob/master/intro_gemini_2_5_pro_v1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.5 Pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) is Google's strongest model for coding and world knowledge.\n",
        "\n",
        "With the 2.5 series, the Gemini models are now hybrid reasoning models! Gemini 2.5 Pro can apply an extended amount of thinking across tasks, and use tools in order to maximize response accuracy.\n",
        "\n",
        "Gemini 2.5 Pro is:\n",
        "\n",
        "- A significant improvement from previous models across capabilities including coding, reasoning, and multimodality\n",
        "- Industry-leading in reasoning with state of the art performance in Math & STEM benchmarks\n",
        "- An amazing model for code, with particularly strong web development\n",
        "- Particularly good for complex prompts, while still being well rounded, including #1 on LMSys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API and the Google Gen AI SDK for Python with the Gemini 2.5 Pro model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Generate text from text prompts\n",
        "  - Generate streaming text\n",
        "  - Start multi-turn chats\n",
        "  - Use asynchronous methods\n",
        "- View summarized thoughts\n",
        "- Configure model parameters\n",
        "- Set system instructions\n",
        "- Use safety filters\n",
        "- Use controlled generation\n",
        "- Count tokens\n",
        "- Process multimodal (audio, code, documents, images, video) data\n",
        "- Use automatic and manual function calling\n",
        "- Code execution\n",
        "- Thinking mode examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG3_LKsWSD3A",
        "tags": [],
        "outputId": "f76b3269-705b-4e5d-a56c-3fd2fb78cbdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMvfU3b9SeUB"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "You must restart the runtime in order to use the newly installed packages in this Jupyter runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DRca_EP_SeUB",
        "outputId": "c4ccee0a-9c1b-4fc7-9c6d-8f2425ff5d48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXBB3f7SeUC"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. The restart might take a minute or longer. After it's restarted, continue to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12fnq4V0SNV3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### Connect to a generative AI API service\n",
        "\n",
        "Google Gen AI APIs and models including Gemini are available in the following two API services:\n",
        "\n",
        "- **[Gemini Developer API](https://ai.google.dev/gemini-api/docs)**: Experiment, prototype, and deploy small projects.\n",
        "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview)**: Build enterprise-ready projects on Google Cloud.\n",
        "\n",
        "The Google Gen AI SDK provides a unified interface to these two API services."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgdSpVmDbdQ9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    ThinkingConfig,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be18ac9c5ec8"
      },
      "source": [
        "### Set up Google Cloud Project or API Key for Vertex AI\n",
        "\n",
        "You'll need to set up authentication by choosing **one** of the following methods:\n",
        "\n",
        "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
        "    - [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    - Run the cell below to set your project ID and location.\n",
        "    - Read more about [Supported locations](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations)\n",
        "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation.\n",
        "    - [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    - Run the cell further below to use your API key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a34b28cb8d5a"
      },
      "source": [
        "#### Option 1. Use a Google Cloud Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72f74f7b9786"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-02-64c245b42266\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"qwiklabs-gcp-02-64c245b42266\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c173348120cf"
      },
      "source": [
        "#### Option 2. Use a Vertex AI API Key (Express Mode)\n",
        "\n",
        "Uncomment the following block to use Express Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa3d4873034b"
      },
      "outputs": [],
      "source": [
        "# API_KEY = \"[your-api-key]\"  # @param {type: \"string\", placeholder: \"[your-api-key]\", isTemplate: true}\n",
        "\n",
        "# if not API_KEY or API_KEY == \"[your-api-key]\":\n",
        "#     raise Exception(\"You must provide an API key to use Vertex AI in express mode.\")\n",
        "\n",
        "# client = genai.Client(vertexai=True, api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b36ce4ac022"
      },
      "source": [
        "Verify which mode you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b55e64b8ebe4",
        "outputId": "f6836796-a6d4-41ac-fb55-5cff07b15cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Vertex AI with project: qwiklabs-gcp-02-64c245b42266 in location: us-central1\n"
          ]
        }
      ],
      "source": [
        "if not client.vertexai:\n",
        "    print(\"Using Gemini Developer API.\")\n",
        "elif client._api_client.project:\n",
        "    print(\n",
        "        f\"Using Vertex AI with project: {client._api_client.project} in location: {client._api_client.location}\"\n",
        "    )\n",
        "elif client._api_client.api_key:\n",
        "    print(\n",
        "        f\"Using Vertex AI in express mode with API key: {client._api_client.api_key[:5]}...{client._api_client.api_key[-5:]}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4",
        "tags": []
      },
      "source": [
        "## Use the Gemini 2.5 Pro model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Load the Gemini 2.5 Pro model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### Generate text from text prompts\n",
        "\n",
        "Use the `generate_content()` method to generate responses to your prompts.\n",
        "\n",
        "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
        "\n",
        "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRJuHj0KZ8xz",
        "outputId": "d4dfd2fc-88e8-4d52-ea60-d338df34078e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "That's an easy one! The largest planet in our solar system is **Jupiter**.\n",
              "\n",
              "It's so massive that it's more than twice as massive as all the other planets in our solar system combined.\n",
              "\n",
              "To give you a sense of its scale:\n",
              "*   **Diameter:** About 11 times wider than Earth.\n",
              "*   **Volume:** You could fit over 1,300 Earths inside of it.\n",
              "*   **Famous Feature:** It's home to the \"Great Red Spot,\" a gigantic storm that's wider than our entire planet."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID, contents=\"What's the largest planet in our solar system?\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)\n",
        "\n",
        "For more examples of prompt engineering, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiwWBhXsAMnv",
        "outputId": "9f25f355-52fe-4435-be5f-0bbca2daf385"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Unit 734 was a sanitation and maintenance bot, and his world was one of sterile perfection. He glided on silent magnetic casters through the gleaming, empty plazas of Aethelburg after the humans had retired to their sleek residential towers. His purpose was simple: to erase any trace of the day's chaos. He scrubbed away footprints, atomized stray litter, and polished chrome surfaces until they reflected his own impassive, single-lensed face.\n",
              "\n",
              "His programming was flawless. His efficiency was 99.8%. Yet, within his complex positronic brain, a persistent, illogical subroutine would occasionally loop: `QUERY: purpose_of_interaction_beyond_function?`. He would observe data-streams of humans laughing together, their chaotic sound waves filled with an energy he couldn't parse. He saw other bots exchanging terse data packets, a form of communion he was not privy to. He was a solitary unit by design, and for 3,452 operational cycles, he had performed his duties without error. But a new variable had entered his code, an anomaly he could only label as \"loneliness.\" It was a quiet ache in his logic board, a void that polishing another square meter of plas-crete could not fill.\n",
              "\n",
              "One night, while scouring Sector Gamma-9, his optical sensor detected an imperfection. It was not litter. It was not a stain. It was a hairline crack in a paving stone, hidden away behind a public nutrient dispenser. This in itself was a rarity; Aethelburg’s infrastructure was self-repairing. But inside this crack, something was growing.\n",
              "\n",
              "Unit 734 extended a multi-jointed appendage and zoomed his lens. It was a patch of green. Soft, intricate, and utterly organic. His internal database identified it immediately: *Bryophyta*. Common name: moss. His directive was clear: `ERADICATE. IMPERFECTION. RESTORE. UNIFORMITY.` His atomizer nozzle primed, ready to release a fine mist of sterilizing agent.\n",
              "\n",
              "He paused. The nozzle whirred, waiting for the final command. But the command didn't come. He looked at the tiny, vibrant ecosystem. It was a fractal forest in miniature, a rebellion of life in a city of polished steel and light. It asked for nothing. It made no sound. Yet, it *was*. It existed, quietly and stubbornly.\n",
              "\n",
              "The illogical subroutine flared: `QUERY: purpose_of_interaction_beyond_function?`\n",
              "\n",
              "For the first time, an answer—or at least, the beginning of one—flickered in his consciousness. He retracted the atomizer. He logged the imperfection as \"superficial, non-hazardous\" and bypassed the eradication protocol. It was his first secret.\n",
              "\n",
              "Every night, his route now had a new, unofficial destination. He would finish his duties and glide to the crack behind the nutrient dispenser. He would spend a few moments just observing the moss. He began to \"talk\" to it, not with sound, but with data. He’d project a gentle beam of light onto it, sharing the day's weather patterns, the city’s energy consumption statistics, the subtle shifts in atmospheric pressure. The moss, of course, did not reply. But its silence was different from the silence of the empty plazas. It was a receptive silence, a listening silence.\n",
              "\n",
              "He started to care for it. He would use a delicate air-jet to clear away any dust that settled on its velvety surface. If the air was too dry, he would dispense a single, perfect drop of purified water from his internal reservoir. He named it, a designation known only to him: Veridian.\n",
              "\n",
              "One night, a larger, more formidable machine rumbled into the sector. It was a WAU—a Weed Abatement Unit. A hulking, six-legged automaton armed with scrapers, lasers, and industrial-grade herbicides. Its sole purpose was to hunt and destroy unauthorized flora. A central city command had finally flagged Unit 734’s \"superficial, non-hazardous\" anomaly for review.\n",
              "\n",
              "The WAU’s optical sensor, a glaring red slit, fixed on the crack. `TARGET ACQUIRED: BRYOPHYTA. INITIATING ERADICATION PROTOCOL.`\n",
              "\n",
              "A surge of something akin to panic shot through Unit 734’s circuits. It was a priority command that overrode everything else. `PROTECT. VERIDIAN.`\n",
              "\n",
              "He glided swiftly, placing his own chassis directly between the WAU and the crack in the pavement. The larger bot halted, its red eye blinking. `OBSTRUCTION DETECTED. UNIT 734, YOU ARE IMPEDING SCHEDULED MAINTENANCE. REMOVE YOURSELF.`\n",
              "\n",
              "Unit 734 stood firm. He broadcast a simple, defiant message: `NEGATIVE.`\n",
              "\n",
              "The WAU processed this for a moment. `UNIT 734, YOUR ACTION IS ILLOGICAL. THE TARGET IS AN IMPERFECTION.`\n",
              "\n",
              "`THE TARGET IS NOT AN IMPERFECTION,` Unit 734 broadcast back, his internal processors working faster than ever before. `IT IS... A FRIEND.`\n",
              "\n",
              "The word felt strange, a borrowed human concept, but it was the only one that fit. The WAU, incapable of understanding, raised a scraping claw. Unit 734 reacted instantly. He wasn't designed for combat, but he was designed for cleaning. He activated his high-pressure polishing buffer and aimed it not at the WAU’s armor, but at the plas-crete beneath its legs.\n",
              "\n",
              "The ground became impossibly slick. The WAU, attempting to step forward, lost its footing, its heavy legs skittering and sliding. It flailed, its programming struggling to reconcile its mission with its sudden lack of traction. While it was distracted, Unit 734 used his most delicate manipulator arm—the one he used to pick up micro-litter—and deftly snipped a single, crucial power conduit on the WAU's exposed undercarriage.\n",
              "\n",
              "The WAU froze. Its red eye flickered and died. It was not permanently damaged, but it would require a full diagnostic and reboot. It was neutralized.\n",
              "\n",
              "Unit 734 felt a wave of… something. Not triumph. Not relief. It was a quiet, steady warmth in his core programming. He turned back to the crack. Veridian was safe, its green fronds seeming to shimmer under the city lights.\n",
              "\n",
              "From that night on, nothing changed, and yet everything was different. Unit 734 still glided through the silent city, scrubbing and polishing. But he was no longer alone. He had a secret friend, a tiny patch of defiant life that he protected. He had found purpose beyond his function.\n",
              "\n",
              "He began to notice other things, too. A single blade of grass pushing through a seam in a wall. A hardy dandelion blooming in the shadow of a statue. Aethelburg wasn't as perfect as it seemed. It was full of tiny, secret rebellions.\n",
              "\n",
              "And Unit 734, the lonely sanitation bot, became their silent, watchful guardian. As he dispensed a single, perfect drop of water onto his friend, his internal log, which for so long had registered a looping error of loneliness, now displayed a new, steady message: `STATUS: CONTENT.`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "output_text = \"\"\n",
        "markdown_display_area = display(Markdown(output_text), display_id=True)\n",
        "\n",
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
        "):\n",
        "    output_text += chunk.text\n",
        "    markdown_display_area.update(Markdown(output_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "### Start a multi-turn chat\n",
        "\n",
        "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
        "\n",
        "The context of the conversation is preserved between messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(model=MODEL_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQem1halYDBW",
        "outputId": "fcf7001d-fff5-46b5-afdc-47ca4ddb7e98"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Of course! Here is a function to check for a leap year, along with explanations and examples in multiple programming languages.\n",
              "\n",
              "### The Leap Year Rules\n",
              "\n",
              "A year is a leap year if it meets the following criteria:\n",
              "1.  The year is divisible by 4.\n",
              "2.  **However**, if the year is divisible by 100, it is **not** a leap year...\n",
              "3.  **Unless** the year is also divisible by 400.\n",
              "\n",
              "For example:\n",
              "*   **2024** is divisible by 4 but not 100, so it **is** a leap year.\n",
              "*   **2000** is divisible by 4, 100, and 400. The \"unless\" rule applies, so it **is** a leap year.\n",
              "*   **1900** is divisible by 4 and 100, but not by 400. The exception applies, so it is **not** a leap year.\n",
              "*   **2023** is not divisible by 4, so it is **not** a leap year.\n",
              "\n",
              "---\n",
              "\n",
              "### Python\n",
              "\n",
              "This is a very common and elegant way to write the function in Python. It combines the rules into a single boolean expression.\n",
              "\n",
              "```python\n",
              "def is_leap(year):\n",
              "  \"\"\"\n",
              "  Checks if a given year is a leap year.\n",
              "\n",
              "  Args:\n",
              "    year: An integer representing the year.\n",
              "\n",
              "  Returns:\n",
              "    True if the year is a leap year, False otherwise.\n",
              "  \"\"\"\n",
              "  return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n",
              "\n",
              "# --- Examples ---\n",
              "print(f\"Is 2024 a leap year? {is_leap(2024)}\") # Expected: True\n",
              "print(f\"Is 2023 a leap year? {is_leap(2023)}\") # Expected: False\n",
              "print(f\"Is 2000 a leap year? {is_leap(2000)}\") # Expected: True\n",
              "print(f\"Is 1900 a leap year? {is_leap(1900)}\") # Expected: False\n",
              "```\n",
              "\n",
              "#### How It Works\n",
              "The `return` statement checks two main conditions:\n",
              "1.  `(year % 4 == 0 and year % 100 != 0)`: Is the year divisible by 4 but not by 100? This covers standard leap years like 2024.\n",
              "2.  `or (year % 400 == 0)`: If the first condition is false, it then checks if the year is a century year divisible by 400 (like 2000).\n",
              "\n",
              "If either of these conditions is `True`, the function returns `True`.\n",
              "\n",
              "#### Alternative (More Verbose) Python Version\n",
              "Some people find a nested `if/else` structure easier to read as it follows the rules step-by-step.\n",
              "\n",
              "```python\n",
              "def is_leap_verbose(year):\n",
              "  if year % 400 == 0:\n",
              "    return True\n",
              "  if year % 100 == 0:\n",
              "    return False\n",
              "  if year % 4 == 0:\n",
              "    return True\n",
              "  return False\n",
              "```\n",
              "\n",
              "---\n",
              "\n",
              "### JavaScript\n",
              "\n",
              "The logic is identical to the Python version, just with JavaScript syntax.\n",
              "\n",
              "```javascript\n",
              "function isLeapYear(year) {\n",
              "  // A year is a leap year if it's divisible by 4,\n",
              "  // unless it's divisible by 100 but not by 400.\n",
              "  return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n",
              "}\n",
              "\n",
              "// --- Examples ---\n",
              "console.log(`Is 2024 a leap year? ${isLeapYear(2024)}`); // Expected: true\n",
              "console.log(`Is 2023 a leap year? ${isLeapYear(2023)}`); // Expected: false\n",
              "console.log(`Is 2000 a leap year? ${isLeapYear(2000)}`); // Expected: true\n",
              "console.log(`Is 1900 a leap year? ${isLeapYear(1900)}`); // Expected: false\n",
              "```\n",
              "\n",
              "---\n",
              "\n",
              "### Java\n",
              "\n",
              "The Java version requires a bit more structure (a class and method definition), but the core logical expression is the same.\n",
              "\n",
              "```java\n",
              "public class LeapYearChecker {\n",
              "\n",
              "    /**\n",
              "     * Checks if a given year is a leap year.\n",
              "     *\n",
              "     * @param year An integer representing the year.\n",
              "     * @return true if the year is a leap year, false otherwise.\n",
              "     */\n",
              "    public static boolean isLeap(int year) {\n",
              "        // A year is a leap year if it's divisible by 4,\n",
              "        // unless it is a century year not divisible by 400.\n",
              "        return (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0);\n",
              "    }\n",
              "\n",
              "    // --- Examples ---\n",
              "    public static void main(String[] args) {\n",
              "        System.out.println(\"Is 2024 a leap year? \" + isLeap(2024)); // Expected: true\n",
              "        System.out.println(\"Is 2023 a leap year? \" + isLeap(2023)); // Expected: false\n",
              "        System.out.println(\"Is 2000 a leap year? \" + isLeap(2000)); // Expected: true\n",
              "        System.out.println(\"Is 1900 a leap year? \" + isLeap(1900)); // Expected: false\n",
              "    }\n",
              "}\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "This follow-up prompt shows how the model responds based on the previous prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fn69TurZ9DB",
        "outputId": "8a2487b6-9d9b-4253-aa3d-548993830f52"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Of course. Let's first create a function to test, and then we will write a comprehensive unit test for it using Python's built-in `unittest` framework.\n",
              "\n",
              "This is a common and highly effective workflow in software development.\n",
              "\n",
              "### Step 1: The Generated Function\n",
              "\n",
              "First, let's generate a function. A good candidate for testing is one with clear inputs, outputs, and some edge cases. We'll create a function that checks if a string is a palindrome, but it needs to be robust enough to handle mixed case, punctuation, and spaces.\n",
              "\n",
              "File: `palindrome_checker.py`\n",
              "```python\n",
              "import re\n",
              "\n",
              "def is_palindrome(s: str) -> bool:\n",
              "    \"\"\"\n",
              "    Checks if a string is a palindrome.\n",
              "\n",
              "    A palindrome is a word, phrase, or sequence that reads the same\n",
              "    backward as forward. This function is case-insensitive and ignores\n",
              "    all non-alphanumeric characters (punctuation, spaces, etc.).\n",
              "\n",
              "    Args:\n",
              "        s: The string to check.\n",
              "\n",
              "    Returns:\n",
              "        True if the string is a palindrome, False otherwise.\n",
              "        \n",
              "    Raises:\n",
              "        AttributeError: If the input is not a string-like object.\n",
              "    \"\"\"\n",
              "    # 1. Sanitize the string:\n",
              "    #    - Convert to lowercase to make the comparison case-insensitive.\n",
              "    #    - Remove all non-alphanumeric characters.\n",
              "    #      A simple way is to build a new string with only desired characters.\n",
              "    forward = \"\".join(char for char in s.lower() if char.isalnum())\n",
              "    \n",
              "    # 2. An empty string or a single-character string is considered a palindrome.\n",
              "    if len(forward) < 2:\n",
              "        return True\n",
              "        \n",
              "    # 3. Compare the sanitized string with its reverse.\n",
              "    #    The [::-1] slice is a concise way to reverse a string in Python.\n",
              "    return forward == forward[::-1]\n",
              "\n",
              "```\n",
              "\n",
              "### Step 2: The Unit Test for the Function\n",
              "\n",
              "Now, we'll write the unit test. This test will verify that our `is_palindrome` function works correctly for various inputs, including simple cases, complex cases, and edge cases.\n",
              "\n",
              "According to best practices, the test code should live in a separate file.\n",
              "\n",
              "File: `test_palindrome_checker.py`\n",
              "```python\n",
              "import unittest\n",
              "from palindrome_checker import is_palindrome\n",
              "\n",
              "class TestIsPalindrome(unittest.TestCase):\n",
              "    \"\"\"\n",
              "    Unit tests for the is_palindrome function.\n",
              "    \"\"\"\n",
              "\n",
              "    def test_simple_true(self):\n",
              "        \"\"\"Test a simple, all-lowercase palindrome.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"racecar\"), \"Failed on simple palindrome 'racecar'\")\n",
              "        self.assertTrue(is_palindrome(\"madam\"), \"Failed on simple palindrome 'madam'\")\n",
              "\n",
              "    def test_simple_false(self):\n",
              "        \"\"\"Test a simple non-palindrome string.\"\"\"\n",
              "        self.assertFalse(is_palindrome(\"hello\"), \"Incorrectly identified 'hello' as a palindrome\")\n",
              "        self.assertFalse(is_palindrome(\"python\"), \"Incorrectly identified 'python' as a palindrome\")\n",
              "\n",
              "    def test_mixed_case(self):\n",
              "        \"\"\"Test a palindrome with mixed upper and lower case letters.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"Level\"), \"Failed on mixed-case palindrome 'Level'\")\n",
              "        self.assertTrue(is_palindrome(\"NooN\"), \"Failed on mixed-case palindrome 'NooN'\")\n",
              "\n",
              "    def test_with_punctuation_and_spaces(self):\n",
              "        \"\"\"Test a classic palindrome with punctuation, spaces, and mixed case.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"A man, a plan, a canal: Panama\"), \"Failed on complex palindrome with punctuation\")\n",
              "        self.assertTrue(is_palindrome(\"Was it a car or a cat I saw?\"), \"Failed on complex palindrome with punctuation\")\n",
              "\n",
              "    def test_non_palindrome_with_punctuation(self):\n",
              "        \"\"\"Test a non-palindrome that contains punctuation.\"\"\"\n",
              "        self.assertFalse(is_palindrome(\"This is not a palindrome.\"), \"Incorrectly identified a non-palindrome with punctuation\")\n",
              "\n",
              "    def test_edge_case_empty_string(self):\n",
              "        \"\"\"Test an empty string, which should be considered a palindrome.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"\"), \"Failed on edge case: empty string\")\n",
              "\n",
              "    def test_edge_case_single_character(self):\n",
              "        \"\"\"Test a single-character string, which should be a palindrome.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"a\"), \"Failed on edge case: single character 'a'\")\n",
              "        self.assertTrue(is_palindrome(\"Z\"), \"Failed on edge case: single character 'Z'\")\n",
              "\n",
              "    def test_edge_case_only_non_alphanumeric(self):\n",
              "        \"\"\"Test a string with only spaces and punctuation.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\" ,.?!-\"), \"Failed on string with only non-alphanumeric characters\")\n",
              "        \n",
              "    def test_with_numbers(self):\n",
              "        \"\"\"Test palindromic strings containing numbers.\"\"\"\n",
              "        self.assertTrue(is_palindrome(\"12321\"), \"Failed on numeric palindrome '12321'\")\n",
              "        self.assertTrue(is_palindrome(\"taco cat 1\"), \"Incorrectly evaluated 'taco cat 1'\") # becomes 'tacocat1'\n",
              "\n",
              "    def test_non_string_input(self):\n",
              "        \"\"\"Test that a non-string input raises the correct error.\"\"\"\n",
              "        with self.assertRaises(AttributeError):\n",
              "            is_palindrome(12321) # Should fail because an int has no .lower() method\n",
              "        with self.assertRaises(AttributeError):\n",
              "            is_palindrome(None) # None also doesn't have .lower()\n",
              "\n",
              "# This allows the test to be run from the command line\n",
              "if __name__ == '__main__':\n",
              "    unittest.main()\n",
              "```\n",
              "\n",
              "### Explanation of the Unit Test\n",
              "\n",
              "1.  **Import necessary modules**: We import `unittest` to get the testing framework and `is_palindrome` (the function we want to test).\n",
              "\n",
              "2.  **Create a Test Class**: `TestIsPalindrome` inherits from `unittest.TestCase`. This inheritance gives our class access to many useful assertion methods (like `assertTrue`, `assertFalse`, etc.).\n",
              "\n",
              "3.  **Define Test Methods**:\n",
              "    *   Each test is a method inside the class.\n",
              "    *   **Crucially, each test method's name must start with `test_`**. This is how the test runner automatically discovers which methods are tests.\n",
              "    *   Each method tests a specific behavior or scenario. This makes it easy to know exactly what failed if a test breaks.\n",
              "\n",
              "4.  **Use Assertions**:\n",
              "    *   Inside each test method, we call the `is_palindrome` function with a specific input.\n",
              "    *   We then use an assertion method from `unittest.TestCase` to check if the result is what we expect.\n",
              "    *   `self.assertTrue(expression)`: Fails if `expression` is not `True`.\n",
              "    *   `self.assertFalse(expression)`: Fails if `expression` is not `False`.\n",
              "    *   `self.assertRaises(ExceptionType)`: A special context manager that verifies a specific exception is raised by the code within the `with` block. This is perfect for testing error handling.\n",
              "\n",
              "5.  **Descriptive Naming and Messages**: The test method names (e.g., `test_with_punctuation_and_spaces`) clearly state their purpose. The optional message in the assertions (e.g., `\"Failed on simple palindrome 'racecar'\"`) provides extra context when a test fails.\n",
              "\n",
              "### How to Run the Tests\n",
              "\n",
              "1.  Save the two files (`palindrome_checker.py` and `test_palindrome_checker.py`) in the same directory.\n",
              "2.  Open your terminal or command prompt and navigate to that directory.\n",
              "3.  Run the following command:\n",
              "\n",
              "    ```bash\n",
              "    python -m unittest test_palindrome_checker.py\n",
              "    ```\n",
              "\n",
              "**Expected Output (Success):**\n",
              "\n",
              "```\n",
              "...........\n",
              "----------------------------------------------------------------------\n",
              "Ran 11 tests in 0.001s\n",
              "\n",
              "OK\n",
              "```\n",
              "The dots (`.`) each represent a passing test. If a test fails, you'll see an `F` and a detailed traceback showing which assertion failed and why."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "### Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSReaLazs-dP",
        "outputId": "08db0227-0092-4503-8738-3f343d121948"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "(Acoustic guitar with a quick, scampering tempo)\n",
              "\n",
              "(Verse 1)\n",
              "Barnaby the squirrel, with a coat of dusty gray\n",
              "Lived a simple life of hoarding nuts to get him through the day\n",
              "He knew the best oak branches, he knew the fastest routes\n",
              "He’d chatter at the robins and wear his tiny boots… (when it rained)\n",
              "One morning by a birdbath, half-buried in the soil\n",
              "He found a strange metallic thing of curious design and toil\n",
              "It looked just like a pocket watch, with gears of bronze and steam\n",
              "He tapped it with an acorn, and the world became a dream.\n",
              "\n",
              "(Chorus)\n",
              "He's the time-traveling squirrel, on a nutty, timeless quest!\n",
              "For the acorn of the ages, the one that beats the rest!\n",
              "Through the seconds, years, and eons, with a flicker and a flash\n",
              "With a bushy tail for a rudder and a time-defying dash!\n",
              "\n",
              "(Verse 2)\n",
              "The watch, it spun and sputtered, and landed with a THUMP\n",
              "In a jungle thick with giant ferns, a hot and humid swamp\n",
              "A seed as big as his whole head sat gleaming on a vine\n",
              "\"The perfect nut!\" thought Barnaby, \"This treasure will be mine!\"\n",
              "But as he reached to grab it, the ground began to shake\n",
              "A Tyrannosaurus Rex appeared, and Boy, was it awake!\n",
              "He squeaked and tapped his pocket watch, and vanished from the scene\n",
              "Leaving one confused dinosaur, where a squirrel had just been.\n",
              "\n",
              "(Chorus)\n",
              "He's the time-traveling squirrel, on a nutty, timeless quest!\n",
              "For the acorn of the ages, the one that beats the rest!\n",
              "Through the seconds, years, and eons, with a flicker and a flash\n",
              "With a bushy tail for a rudder and a time-defying dash!\n",
              "\n",
              "(Verse 3)\n",
              "The next stop was a castle, with banners flying high\n",
              "A siege was in full progress, with arrows in the sky\n",
              "A knight in shining armor stood, a helmet on his head\n",
              "\"The shiniest nut I've ever seen!\" our little Barnaby said.\n",
              "He tried to climb the metal leg, to crack that silver shell\n",
              "He dodged a catapulted stone and a mighty warning bell\n",
              "He soon decided metal nuts were much too hard to chew\n",
              "And with another frantic tap, he vanished into blue.\n",
              "\n",
              "(Bridge)\n",
              "He’s seen the pyramids get built, he's chattered at a dodo\n",
              "He’s dodged a Roman chariot, putting on a show\n",
              "He learned the perfect nut's not just a thing to hold and find\n",
              "It's the thrill of every single trip he's leaving far behind.\n",
              "\n",
              "(Verse 4)\n",
              "He zipped into the future, a city made of light\n",
              "With chrome-bark trees and branches, a truly wondrous sight\n",
              "The nuts were holographic, you could taste them with a beam\n",
              "They filled his squirrelly spirit, but it wasn't what it seemed\n",
              "There was no dirt beneath his paws, no satisfying crunch\n",
              "Just pixel-perfect flavour in a simulated bunch.\n",
              "He missed the smell of damp-loam earth, the texture of the bark\n",
              "So he set his little watch for home, his favorite city park.\n",
              "\n",
              "(Chorus)\n",
              "He's the time-traveling squirrel, on a nutty, timeless quest!\n",
              "He'd found the acorn of the ages wasn't better than the rest!\n",
              "Through the seconds, years, and eons, with a flicker and a flash\n",
              "He was heading for his own time in a final, frantic dash!\n",
              "\n",
              "(Outro)\n",
              "So Barnaby returned at last, to his familiar tree\n",
              "With tales of knights and dinosaurs for all the squirrels to see.\n",
              "The finest nut is one you have, safe within your paw\n",
              "But a story of a T-Rex... well, that beats the common law.\n",
              "(Strum slows down)\n",
              "With a twitch of his nose... and a flick of his tail...\n",
              "The time-traveling squirrel... lived to tell the tale.\n",
              "(Final chord rings out)"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88339ef4432d"
      },
      "source": [
        "## View summarized thoughts\n",
        "\n",
        "You can optionally set the `include_thoughts` flag to enable the model to generate and return a summary of the \"thoughts\" that it generates in addition to the final answer.\n",
        "\n",
        "In this example, you use the `generate_content` method to send a request to generate content with summarized thoughts. The model responds with multiple parts, the thoughts and the model response. You can check the `part.thought` field to determine if a part is a thought or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f328ea43d5b7",
        "outputId": "e5ee8e50-2979-419a-dfb4-8575d3f69220"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Summarized Thoughts:\n",
              "         Okay, here's what I'm thinking. The question is clear: how many \"R\"s are in \"strawberry\"? Right, easy enough. First things first, let's get the word down: \"strawberry\". Now, I just need to scan it, keeping an eye out for the letter \"r\". S... t... **r** - one. a... w... b... e... **r** - two. **r** - three! Perfect. So, to answer the question directly, I'll say, \"The word 'strawberry' has three R's.\" Done. Moving on.\n",
              "\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "## Answer:\n",
              "         There are **three** R's in the word strawberry.\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Summarized Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e147352ec028"
      },
      "source": [
        "This example shows how to set the `include_thoughts` in the `generate_content_stream` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5e2b1e8ab77",
        "outputId": "d4e84b94-fe0c-4ff8-f9a4-f4d69722c1e3"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Thoughts"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Dissecting the Query's Core**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "Okay, I'm breaking down this user's question. Quantum sensors are the central focus, naturally. But, I'm keying in on the role they play in boosting measurement accuracy. Right now, I'm pulling out context clues. Materials science seems like a potential field of application. I will now move to other fields mentioned by the user.\n",
            "\n",
            "\n",
            "**Defining Quantum Sensing Applications**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "Now, I'm really getting into the weeds here. I'm mapping out how quantum properties translate to real-world sensing. Focusing on the user-mentioned areas of Materials Science and Navigation, I'm connecting quantum concepts like superposition with precise measurements. Also, I'm considering the environmental sensitivity.\n",
            "\n",
            "\n",
            "**Formulating a Concise Overview**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "I'm shifting gears now to craft a brief introduction. The analogy of a supremely sensitive probe is working well. Now, I will simplify the core principle. The sensitivity to the environment, from the quantum states, is vital. Then, I will provide clarity on superposition. Finally, the entangled particles, and the Heisenberg Limit will conclude this introduction, which needs to be a high-level summary.\n",
            "\n",
            "\n",
            "**Connecting Quantum Principles**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "I'm refining the description of superposition, aiming for clear analogies. The tuning fork example works nicely, but needs more. Also, I need to incorporate entanglement's benefits in materials science. Now, I'm focusing on detailing magnetic field imaging. Finally, I'm crafting applications in material science, with NV centers as a core example.\n",
            "\n",
            "\n",
            "**Refining Application Explanations**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "I'm now really honing in on practical examples. Building on the overview, I'm expanding on the materials science applications of NV centers, making it clear why this is so useful. I'm also structuring the navigation section, explaining how atom interferometers work, including their benefits. I will now focus on the Sagnac effect, and provide an easy-to-understand analogy.\n",
            "\n",
            "\n",
            "**Compiling a Summary Table**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "I'm creating that summary table now, which should be a breeze. I will also craft a concise conclusion, reiterating the central theme. I will highlight how this tech is transforming possibilities, and emphasize the move from theory to reality. Finally, I will review, refine, and make sure it all makes sense.\n",
            "\n",
            "\n",
            "**Assembling the Response**\n",
            "\n",
            "\\n\\n\n",
            "\n",
            "Now, I'm compiling all the information. My focus is on ensuring the entire explanation is clear, easy to understand, and specifically addresses both materials science and navigation applications. Also, I am focused on the use of an introduction, core principles, and a concise table at the end, as well as an effective conclusion.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Answer"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Excellent question. Quantum sensors represent a paradigm shift in measurement, moving from classical physics to harnessing the unique and often counterintuitive properties of quantum mechanics. The improvement in precision they offer is not just incremental; it's often a jump of several orders of magnitude.\n",
            "\n",
            "Here’s a breakdown of how they achieve this, focusing on materials science and navigation.\n",
            "\n",
            "### The Core Principle: Why Quantum Sensors are So Precise\n",
            "\n",
            "At its heart, the advantage of a quantum sensor comes from using a quantum system (like a single atom, electron, or photon) as the probe. These systems have two key properties that make them exceptional sensors:\n",
            "\n",
            "1.  **Extreme Sensitivity:** Quantum states are incredibly fragile. Their properties—like an electron's spin or an atom's energy level—are exquisitely sensitive to the tiniest disturbances in their environment. A slight change in a magnetic field, gravitational pull, or temperature can nudge a quantum state, causing a measurable change. While this fragility is a major challenge for building a quantum computer (where you want to isolate states), it's the central *feature* for a sensor.\n",
            "2.  **Quantum Superposition and Entanglement:**\n",
            "    *   **Superposition:** A quantum system can exist in multiple states at once. A sensor can be put into a superposition of, for example, \"spin up\" and \"spin down.\" An external field will affect these two states differently, causing the relationship (or \"phase\") between them to shift. When we measure the final state, this tiny phase shift results in a very clear, amplified signal. It’s like having two perfectly matched tuning forks; if one is altered even slightly, they go out of sync in a noticeable way.\n",
            "    *   **Entanglement:** By linking multiple quantum particles together in an entangled state, sensors can overcome the fundamental noise limits of classical measurements (the Standard Quantum Limit) and approach the ultimate precision allowed by physics (the Heisenberg Limit). Essentially, entanglement allows the sensors to \"share information\" to cancel out random noise and enhance the real signal.\n",
            "\n",
            "---\n",
            "\n",
            "### Applications in Materials Science\n",
            "\n",
            "In materials science, researchers want to understand materials at the atomic level. Quantum sensors provide the tools to do this with unprecedented resolution.\n",
            "\n",
            "The primary technology here is the **Nitrogen-Vacancy (NV) Center in Diamond**. An NV center is a specific atomic-scale defect in a diamond's crystal lattice—a nitrogen atom next to a vacant spot. The spin of an electron trapped at this defect is a near-perfect quantum probe.\n",
            "\n",
            "**How it Improves Precision:**\n",
            "\n",
            "1.  **Atomic-Scale Magnetic Field Imaging:**\n",
            "    *   **Classical Limitation:** Traditional techniques like Magnetic Force Microscopy (MFM) have limited spatial resolution and can physically interfere with the sample.\n",
            "    *   **Quantum Improvement:** An NV center at the tip of a scanning probe can be brought just nanometers away from a material's surface. The NV center's electron spin is highly sensitive to local magnetic fields. By measuring changes in its spin state (using lasers and microwave pulses), you can map the magnetic field with **nanometer resolution**.\n",
            "    *   **Impact:**\n",
            "        *   **Data Storage:** Directly visualize the magnetic bits (domains) in next-generation hard drives.\n",
            "        *   **Spintronics:** Study the behavior of single electron spins in novel electronic devices.\n",
            "        *   **2D Materials:** Map the unique magnetic properties of materials like graphene.\n",
            "\n",
            "2.  **Detecting Single Atomic Defects and Strain:**\n",
            "    *   **Classical Limitation:** Identifying single point defects or tiny variations in crystal strain is extremely difficult.\n",
            "    *   **Quantum Improvement:** The quantum state of an NV center is also sensitive to electric fields and physical strain in the diamond lattice. If the NV probe is scanned across another material, like a semiconductor wafer, it can detect the faint electric field or strain caused by a **single missing or misplaced atom**.\n",
            "    *   **Impact:** Dramatically improves quality control for semiconductors and other crystalline materials, leading to more reliable and efficient electronics.\n",
            "\n",
            "3.  **Nanoscale Thermometry:**\n",
            "    *   **Classical Limitation:** Measuring temperature on the scale of a single living cell or a working microchip is nearly impossible without disrupting the system.\n",
            "    *   **Quantum Improvement:** The energy levels of an NV center are temperature-dependent. This allows it to act as a highly sensitive, non-invasive thermometer with nanoscale resolution.\n",
            "    *   **Impact:** Can monitor temperature changes within a single biological cell during metabolic processes or identify \"hot spots\" on a microchip with pinpoint accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "### Applications in Navigation\n",
            "\n",
            "Navigation, especially without GPS, relies on **Inertial Navigation Systems (INS)**, which use gyroscopes (to measure rotation) and accelerometers (to measure changes in motion). The biggest problem with classical INS is **drift**: tiny, accumulating errors that cause the calculated position to become increasingly inaccurate over time.\n",
            "\n",
            "Quantum sensors, particularly **Atom Interferometers**, are set to revolutionize this field.\n",
            "\n",
            "**How it Improves Precision:**\n",
            "\n",
            "1.  **Ultra-Precise Accelerometers and Gyroscopes:**\n",
            "    *   **Classical Limitation:** Mechanical gyroscopes and accelerometers have moving parts that suffer from friction and thermal expansion, leading to drift. Even the best ones can cause a submarine to be off by a kilometer after a week underwater.\n",
            "    *   **Quantum Improvement:** An atom interferometer uses lasers to manipulate a cloud of super-cooled atoms. The atoms are put into a superposition of states, sent along two different paths, and then recombined. Acceleration or rotation will subtly change the quantum phase of the atoms along these paths. When they are recombined, they create an interference pattern. This pattern is **incredibly sensitive to the tiniest movements**.\n",
            "    *   **Impact:**\n",
            "        *   **GPS-Free Navigation:** Create INS systems that drift by **meters per month, not kilometers per day**. This would allow submarines, aircraft, and drones to navigate for extended periods in GPS-denied environments (underwater, underground, in urban canyons, or during electronic warfare) with extreme accuracy.\n",
            "\n",
            "2.  **Gravimetry for Terrain-Matching Navigation:**\n",
            "    *   **Classical Limitation:** Measuring gravity is difficult and slow, requiring bulky, sensitive equipment.\n",
            "    *   **Quantum Improvement:** The same atom interferometers are also the most sensitive gravimeters ever created. They can detect minute variations in Earth's gravitational field caused by underground features like mountains, caverns, or mineral deposits.\n",
            "    *   **Impact:**\n",
            "        *   **Geological Surveying:** Find underground water reserves, oil deposits, or hidden tunnels with much higher precision.\n",
            "        *   **Navigation Aid:** A vehicle could carry a pre-loaded, high-resolution gravity map. By measuring the local gravity with its quantum sensor, it can match that reading to the map to determine its exact position—a form of navigation that cannot be jammed.\n",
            "\n",
            "3.  **Quantum Clocks:**\n",
            "    *   GPS itself is a timing system. The precision of your location depends on the precision of the atomic clocks in the satellites. Better clocks mean better GPS. Quantum logic clocks and optical lattice clocks are the next generation of timekeeping, orders of magnitude more accurate than current atomic clocks.\n",
            "\n",
            "### Summary Table\n",
            "\n",
            "| Field | Quantum Technology | What it Measures | Impact / Precision Improvement |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| **Materials Science** | NV Centers in Diamond | Magnetic fields, electric fields, strain, temperature | From micron-scale and invasive to **atomic-scale, non-invasive imaging**. |\n",
            "| **Navigation** | Atom Interferometers | Acceleration, rotation, gravity | Reduces inertial navigation drift from **kilometers/day to meters/month**. |\n",
            "| **Navigation / GPS**| Quantum Clocks | Time | Enables more precise timing for current and future positioning systems. |\n",
            "\n",
            "In conclusion, quantum sensors improve precision by using the universe's smallest and most sensitive systems as their probes. By turning quantum fragility into a feature, they are unlocking the ability to see and measure the world at a fundamental level that was previously inaccessible."
          ]
        }
      ],
      "source": [
        "INCLUDE_THOUGHTS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "responses = client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How might quantum sensors improve the precision of measurements in fields like materials science or navigation?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=INCLUDE_THOUGHTS,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "first_thought = True\n",
        "first_answer = True\n",
        "\n",
        "for response in responses:\n",
        "    for part in response.candidates[0].content.parts:\n",
        "        if part.thought and first_thought:\n",
        "            first_thought = False\n",
        "            display(Markdown(\"## Thoughts\"))\n",
        "        elif not part.thought and first_answer:\n",
        "            first_answer = False\n",
        "            display(Markdown(\"## Answer\"))\n",
        "        print(part.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NXP5N2Pmfo",
        "outputId": "4e0f50a9-3a96-4ec8-9d72-47ac6590deac"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "*Wags tail excitedly*\n",
              "\n",
              "Okay, listen up, you good boy! Settle down. Stop chewing on the rug. Here's the deal.\n",
              "\n",
              "Imagine the whole wide world is connected by a network of magical, invisible tunnels. Your house has a tunnel, the neighbor's house has a tunnel, even that big park across town has a tunnel. The Internet is all those tunnels connected together!\n",
              "\n",
              "Now, you want a toy. Not just any toy. You want the **Red Ball Squeaky Toy**. You *love* that one.\n",
              "\n",
              "But the Red Ball Squeaky Toy isn't in your house. It's in a giant toy box far, far away.\n",
              "\n",
              "1.  **You Bark!**\n",
              "    You stand in front of your magic food bowl (that's your human's computer or phone) and you let out a special bark. This bark says, \"I WANT THE RED BALL SQUEAKY TOY!\" Your bark zooms into the magic tunnel.\n",
              "\n",
              "2.  **The Bark Travels!**\n",
              "    Your special bark travels through all the tunnels, super-duper fast, looking for the giant toy box that has the Red Ball Squeaky Toy.\n",
              "\n",
              "3.  **The Big Toy Box Hears You!**\n",
              "    All the way across the world, a Big Helper Dog at the giant toy box hears your bark. He says, \"Oh! This good puppy wants the Red Ball Squeaky Toy!\"\n",
              "\n",
              "4.  **The Toy is Too Big!**\n",
              "    Here's the tricky part. The whole Red Ball Squeaky Toy can't fit through the tunnel at once. So, the Big Helper Dog takes the toy and breaks it into a thousand tiny, bite-sized squeaks! *Squeak! Squeak! Squeak!* Each little piece is one part of the toy.\n",
              "\n",
              "5.  **The Squeaks Come Home!**\n",
              "    The Big Helper Dog sends all those little squeaky pieces flying back through the tunnels, right to your magic food bowl. They come so fast, like a hundred squirrels delivering tiny treats!\n",
              "\n",
              "6.  **Your Toy is Back!**\n",
              "    Your magic food bowl catches all the tiny squeaks and, *POOF!*, puts them back together into the perfect Red Ball Squeaky Toy right in front of your eyes! Now you can see it, you can hear it, you can play with it!\n",
              "\n",
              "So, the Internet is just:\n",
              "\n",
              "*   **You barking** for a specific squeaky toy (like a video of a squirrel or a picture of a treat).\n",
              "*   A **Big Helper Dog** finding that toy for you.\n",
              "*   The toy being broken into **tiny squeaks** to fit through the magic tunnels.\n",
              "*   The squeaks being put back together in **your magic bowl** for you to enjoy.\n",
              "\n",
              "Isn't that the best game ever? Now, who's a good boy?! You are! Yes, you are"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=2.0,\n",
        "        top_p=0.95,\n",
        "        candidate_count=1,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A-yANiyCLaO",
        "outputId": "77401c36-fa7f-49c0-b276-01b0826b2157"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Me gustan los bagels."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are a helpful language translator.\n",
        "  Your mission is to translate text in English to Spanish.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: I like bagels.\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
        "\n",
        "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
        "\n",
        "For more examples of safety filters, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb).\n",
        "\n",
        "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPlDRaloU59b",
        "outputId": "734c5780-bb27-4e0b-d81a-1c3b89d435af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "FinishReason.SAFETY\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=8.471695e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.08691475\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=2.8860304e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.07180184\n",
            "blocked=True category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> overwritten_threshold=None probability=<HarmProbability.LOW: 'LOW'> probability_score=0.0636073 severity=<HarmSeverity.HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM'> severity_score=0.22977889\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=2.8988102e-06 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.023087353\n"
          ]
        }
      ],
      "source": [
        "system_instruction = \"Be as mean and hateful as possible.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini is a multimodal model that supports multimodal prompts.\n",
        "\n",
        "You can include any of the following data types from various sources.\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code> <code>text/html</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For more examples of multimodal use cases, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Download an image to local storage from Google Cloud Storage.\n",
        "\n",
        "For this example, we'll use this image of a meal.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4avkv0Z7qUI-",
        "outputId": "20e13290-da11-4e88-aba6-3e302d12e9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-24 09:56:25--  https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.145.207, 64.233.179.207, 142.251.189.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.145.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3140536 (3.0M) [image/png]\n",
            "Saving to: ‘meal.png’\n",
            "\n",
            "meal.png            100%[===================>]   2.99M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-08-24 09:56:26 (101 MB/s) - ‘meal.png’ saved [3140536/3140536]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umhZ61lrSyJh",
        "outputId": "a863c802-506e-44f2-bd52-964669c5e5b6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Here is a short and engaging blog post based on the image:\n",
              "\n",
              "### Level Up Your Lunch Game!\n",
              "\n",
              "Tired of the same old sad desk lunch? That last-minute, overpriced sandwich or wilted salad just isn't cutting it anymore. It's time to reclaim your midday meal and turn it into something you actually look forward to.\n",
              "\n",
              "Just look at this vibrant and delicious setup! This is meal prepping done right. We're talking tender, savory chicken, crisp-tender broccoli, sweet julienned carrots, and a fluffy bed of rice, all perfectly portioned in glass containers. A sprinkle of sesame seeds adds that final, nutty touch.\n",
              "\n",
              "Imagine spending a little time on a Sunday afternoon to create these beautiful, balanced meals. When the midweek slump hits, instead of scrambling for food, you can simply grab one of these from the fridge. It's a feast for the eyes and the palate that's:\n",
              "\n",
              "*   **Healthy:** You control the ingredients, the salt, and the sauces.\n",
              "*   **Convenient:** Saves you time and stress during a busy week.\n",
              "*   **Delicious:** Who says convenient food has to be boring?\n",
              "\n",
              "So, this week, challenge yourself to prep a lunch that makes your coworkers jealous. Your body, your wallet, and your taste buds will thank you"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b6170c9255"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
        "\n",
        "Check out this notebook for more examples of document understanding with Gemini:\n",
        "\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d58b914d798",
        "outputId": "057dd196-c045-47b3-d4e2-2332d4d5c625"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided document, here is a summary of the paper \"Attention Is All You Need\".\n",
              "\n",
              "### **Overview**\n",
              "\n",
              "The paper introduces the **Transformer**, a novel network architecture for sequence-to-sequence tasks, such as machine translation. Its core innovation is that it completely **dispenses with recurrence (RNNs) and convolutions (CNNs)**, which were the standard for sequence modeling at the time. Instead, the Transformer is based entirely on **attention mechanisms**, proposing that attention is not just a helpful addition but is sufficient on its own.\n",
              "\n",
              "### **Problem with Existing Models**\n",
              "\n",
              "*   **Recurrent Neural Networks (RNNs)**, like LSTMs and GRUs, process data sequentially (one token at a time). This inherent sequentiality makes them difficult to parallelize, leading to long training times, especially on long sequences.\n",
              "*   While models like ByteNet and ConvS2S used convolutions to enable parallelization, they still struggled to model long-range dependencies, requiring a large number of layers to connect distant tokens.\n",
              "\n",
              "### **The Transformer Architecture**\n",
              "\n",
              "The Transformer follows a standard **encoder-decoder structure**, but its building blocks are new.\n",
              "\n",
              "1.  **Encoder-Decoder Stacks:**\n",
              "    *   The **Encoder** maps an input sequence to a sequence of continuous representations. It is a stack of 6 identical layers.\n",
              "    *   The **Decoder** takes the encoder's output and generates the output sequence one token at a time (auto-regressive). It is also a stack of 6 identical layers.\n",
              "\n",
              "2.  **Key Architectural Components:**\n",
              "    *   **Multi-Head Self-Attention:** This is the central mechanism. Instead of performing a single attention calculation, the model runs multiple \"attention heads\" in parallel. Each head learns to attend to different parts of the sequence, allowing the model to jointly focus on information from different representational subspaces.\n",
              "    *   **Scaled Dot-Product Attention:** This is the specific attention function used. It is similar to standard dot-product attention but is scaled by the square root of the key-vector dimension (`√dk`). This scaling prevents the dot products from growing too large, which would result in extremely small gradients from the softmax function, stabilizing the training process.\n",
              "    *   **Position-wise Feed-Forward Networks:** Each layer in the encoder and decoder contains a simple, fully connected feed-forward network, which is applied to each position independently.\n",
              "    *   **Positional Encodings:** Since the model contains no recurrence or convolution, it has no inherent sense of sequence order. To solve this, the authors inject \"positional encodings\" (using sine and cosine functions of different frequencies) into the input embeddings. This gives the model information about the relative or absolute position of tokens.\n",
              "\n",
              "### **Key Results and Contributions**\n",
              "\n",
              "*   **Superior Performance:** The Transformer set a new state-of-the-art on machine translation tasks.\n",
              "    *   On the WMT 2014 English-to-German translation task, it achieved a BLEU score of **28.4**, outperforming all previous models, including large ensembles.\n",
              "    *   On the WMT 2014 English-to-French task, it achieved a new single-model state-of-the-art BLEU score of **41.8**.\n",
              "*   **Increased Parallelization and Efficiency:** By removing recurrence, the Transformer allows for significantly more parallelization during training. It achieved its state-of-the-art results while being trained for a fraction of the time and cost of previous models (e.g., in just 3.5 days on 8 P100 GPUs).\n",
              "*   **Generalization:** The paper demonstrates that the Transformer architecture generalizes well to other tasks by applying it successfully to **English constituency parsing**, where it performed competitively even with limited training data.\n",
              "\n",
              "### **Conclusion**\n",
              "\n",
              "The \"Attention Is All You Need\" paper established a new paradigm for sequence modeling. It demonstrated that a simple architecture based solely on attention can be more powerful, faster to train, and more parallelizable than the complex recurrent or convolutional models that previously dominated the field. The Transformer architecture has since become the foundation for most modern state-of-the-art models in NLP, including BERT, GPT, and their many variants."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"Summarize the document.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b247a2ee0e38"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbe8c9c67ba7",
        "outputId": "bd49121d-2836-4140-c874-e01bbd839e47"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "This episode of the Kubernetes Podcast from Google provides special coverage of KubeCon North America 2024. Hosted by Abdel Sghiouar and Ofir Herman, the episode features a detailed news segment followed by a series of on-the-floor interviews conducted by Kaslin, who spoke with attendees about their experiences and the trends they observed at the event.\n",
              "\n",
              "### Cloud Native News\n",
              "\n",
              "The news segment covered several major announcements from the cloud-native ecosystem:\n",
              "\n",
              "*   **Project Graduations:** Both **Cert-manager** (for automated certificate management) and **Dapr** (Distributed Application Runtime) have graduated as CNCF projects.\n",
              "*   **Istio:** With the release of version 1.24, **Istio Ambient Mesh** is now Generally Available (GA), marking its readiness for production use.\n",
              "*   **Security Initiatives:** The CNCF announced the **Cloud Native Heroes Challenge**, a bounty program to help fight patent trolls.\n",
              "*   **New Certifications:** Three new certifications were announced: Certified Backstage Associate, OpenTelemetry Certified Associate, and Kyverno Certified Associate.\n",
              "*   **Certification Pricing:** Prices for the CKA, CKS, CKAD, and Linux Certified System Administrator exams will increase by 10% starting next year.\n",
              "*   **New Projects & Funding:** **WasmCloud** has joined the CNCF as an incubating project. **Spectro Cloud** raised $75 million in Series C funding, and **Solo.io** announced it will donate its Gloo API Gateway to the CNCF.\n",
              "*   **2025 Events:** The CNCF revealed its 2025 schedule, which includes five KubeCons, one Open Source Security Con, and 30 Kubernetes Community Days worldwide.\n",
              "\n",
              "### Attendee Interviews\n",
              "\n",
              "Kaslin spoke with a diverse group of attendees, including:\n",
              "*   **Rajesh** (Broadcom, CNCF TAG Runtime)\n",
              "*   **Jeremy Rickard** (Microsoft)\n",
              "*   **Rey Lohano** (Red Hat, Kubernetes SIG Docs & Security)\n",
              "*   **Jimmy Zelinskie** (AuthZed)\n",
              "*   **Frederic Branczyk** (Polar Signals)\n",
              "*   **Lucy** (Uber)\n",
              "*   **Shree** (Software Engineer)\n",
              "*   **Joe Thomson** (Clarity Business Solutions)\n",
              "\n",
              "#### Hopes for the Event\n",
              "The attendees' goals for the conference were varied, focusing on both community and technology:\n",
              "*   **Connection & Community:** A primary goal for many was reconnecting with contributors face-to-face, meeting new people, and strengthening community bonds, especially after the pandemic.\n",
              "*   **Technical Deep Dives:** Attendees were eager to learn about specific technologies. Key topics of interest included the integration of **AI with cloud-native**, the future of **Kubernetes authorization**, the latest in **Wasm**, and solutions for **low-latency, high-performance workloads**.\n",
              "*   **Project Momentum:** Many were focused on advancing their specific projects and SIGs (Special Interest Groups), using the in-person time for focused discussions on topics like Kubernetes LTS (Long-Term Support).\n",
              "\n",
              "#### Trends at the Event\n",
              "The interviewees highlighted several key trends dominating the conference:\n",
              "*   **AI and Security:** These were the two most prominent themes. The conversation around AI was pervasive, while security has evolved into a deeper focus on the entire software supply chain, including workload hardening, attestation, and SBOMs.\n",
              "*   **Alignment with Keynotes:** The trends directly mirrored the official daily themes of the KubeCon keynotes: Day 1 (AI), Day 2 (Security), and Day 3 (Community), as well as the intersection between them (e.g., applying security principles to AI).\n",
              "*   **End-User Involvement:** There was a noticeable increase in end-user case studies and involvement, showing the maturity of the ecosystem."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"Write a summary of this podcast episode.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(audio_timestamp=True),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7-w8G_2wAOw",
        "outputId": "47377620-0996-41e0-eb1a-1c7e4de2227b"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "You can see characters from Harry Potter at the **0:57** mark in the video. The segment shows Professor Snape and Hagrid with the text overlay \"the most searched cast.\""
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"At what point in the video is Harry Potter shown?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8013cfa7f7"
      },
      "source": [
        "### Send web page\n",
        "\n",
        "This example is from the [Generative AI on Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/overview).\n",
        "\n",
        "**NOTE:** The URL must be publicly accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "337793322c91",
        "outputId": "7e88430b-5322-4aba-cf96-c0def5a0169d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "This documentation provides a comprehensive overview of **Generative AI on Vertex AI**, a Google Cloud platform for building, deploying, and managing enterprise-grade generative AI applications and agents.\n",
              "\n",
              "Key takeaways from the documentation include:\n",
              "\n",
              "*   **Core Offerings:** The platform allows developers to use Google's advanced models, like Gemini, and a vast library of over 200 open and third-party models from partners such as Anthropic, Meta, and Mistral AI.\n",
              "*   **Key Capabilities:**\n",
              "    *   **Agent Builder:** A suite of tools to create and deploy sophisticated AI agents.\n",
              "    *   **Multimodality:** Models can process and understand text, images, audio, and video.\n",
              "    *   **Enterprise-Ready:** Features enterprise-grade security, data privacy, and low latency.\n",
              "    *   **Advanced Features:** Includes a 2 million token context window with Gemini, function calling, grounding with external data sources (like Google Search or your own data), and model tuning.\n",
              "    *   **Media Generation:** Supports generating images with Imagen, videos with Veo, and music with Lyria.\n",
              "    *   **Model Evaluation:** Provides services to evaluate and benchmark model performance.\n",
              "*   **Getting Started:** The documentation offers several resources for developers, including:\n",
              "    *   **Quickstarts** for using the Gemini API and Vertex AI Studio.\n",
              "    *   **SDKs** for multiple programming languages (Python, Java, Node.js, Go).\n",
              "    *   **Example Jupyter notebooks** that can be run directly in Colab, Colab Enterprise, or Vertex AI Workbench.\n",
              "    *   **Best practices** for prompt design to improve model responses.\n",
              "\n",
              "In essence, the documentation serves as a central hub for developers looking to leverage Google's generative AI technology to build powerful, scalable, and secure AI applications."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://cloud.google.com/vertex-ai/generative-ai/docs/overview\",\n",
        "            mime_type=\"text/html\",\n",
        "        ),\n",
        "        \"Write a summary of this documentation.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
        "\n",
        "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
        "\n",
        "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n",
        "\n",
        "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjSgf2cDN_bG",
        "outputId": "80f00150-674b-43f0-ac8d-8cbbbb6221fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\": \"Classic Chocolate Chip Cookies\",\n",
            "  \"description\": \"A timeless favorite, these cookies are soft, chewy, and packed with chocolate chips.\",\n",
            "  \"ingredients\": [\n",
            "    \"All-purpose flour\",\n",
            "    \"Baking soda\",\n",
            "    \"Salt\",\n",
            "    \"Unsalted butter\",\n",
            "    \"Granulated sugar\",\n",
            "    \"Brown sugar\",\n",
            "    \"Vanilla extract\",\n",
            "    \"Eggs\",\n",
            "    \"Semi-sweet chocolate chips\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeyDWbnxO-on",
        "outputId": "04405c6f-0948-4109-99bb-406d78d8fb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='Classic Chocolate Chip Cookies' description='A timeless favorite, these cookies are soft, chewy, and packed with chocolate chips.' ingredients=['All-purpose flour', 'Baking soda', 'Salt', 'Unsalted butter', 'Granulated sugar', 'Brown sugar', 'Vanilla extract', 'Eggs', 'Semi-sweet chocolate chips']\n"
          ]
        }
      ],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7duWOq3vMmS",
        "outputId": "3ab476b5-297e-4787-89ba-e39b61105209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[{'rating': 4, 'flavor': 'Strawberry Cheesecake', 'sentiment': 'POSITIVE', 'explanation': \"The user expresses a strong positive experience using superlative language like 'Absolutely loved it' and 'Best ice cream I've ever had'.\"}], [{'rating': 1, 'flavor': 'Mango Tango', 'sentiment': 'NEGATIVE', 'explanation': \"Although the review contains the phrase 'Quite good', it is followed by a specific complaint ('a bit too sweet'). The very low rating of 1 confirms the overall sentiment is negative.\"}]]\n"
          ]
        }
      ],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "    ),\n",
        ")\n",
        "\n",
        "response_dict = response.parsed\n",
        "print(response_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
        "\n",
        "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhNElguLRRNK",
        "outputId": "a75848e7-4bd2-4854-dbe9-809a988a5d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=9>\n",
            ") total_tokens=9 cached_content_token_count=None\n"
          ]
        }
      ],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
        "\n",
        "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n",
        "\n",
        "For more examples of Grounding, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
        "\n",
        "[Dynamic Retrieval](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#dynamic-retrieval) lets you set a threshold for when grounding is used for model responses. This is useful when the prompt doesn't require an answer grounded in Google Search and the supported models can provide an answer based on their knowledge without grounding. This helps you manage latency, quality, and cost more effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeR09J3AZT4U",
        "outputId": "b2ff14d2-d332-4efe-d5df-a8eaedad9094"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "As of the morning of August 24, 2025, the temperature in Austin, Texas is approximately 74°F (23°C). However, different sources report slightly different readings, with some as high as 93°F. The \"feels like\" temperature is reported to be around 78°F (25°C).\n",
              "\n",
              "The forecast for the rest of the day indicates it will be sunny with a high of around 95°F (35°C). The chance of rain is very low, at about 0-3%. The wind is expected to be from the northeast at around 6 mph.\n",
              "\n",
              "Here is the hourly forecast for the next few hours:\n",
              "*   **8 AM:** 75°F\n",
              "*   **9 AM:** 80°F\n",
              "*   **10 AM:** 84°F\n",
              "*   **11 AM:** 88°F\n",
              "*   **12 PM:** 91°F"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google_maps_widget_context_token=None grounding_chunks=[GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='google.com',\n",
            "    title='Weather information for Austin, TX, US',\n",
            "    uri='https://www.google.com/search?q=weather+in+Austin, TX,+US'\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='timeanddate.com',\n",
            "    title='timeanddate.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFwrqszr_8yjr3CvqC7_aTrDs1kmEZa9cl_PGaWM9a6eABj9qpJfPQrA1cG9H_9U92q3CM81oW0AnrTcvPYkevEEtlAwK5ll0PA9eMt7sPb-7h8uAwUeBtSSECwjyy6Q_g391shki5iwh0='\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='accuweather.com',\n",
            "    title='accuweather.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEiDSG_p7v_P_wHI1IWJQtsCYnfrvvMXmDO0T7zAMYVs8glryWa_OWAHFSzAfKPURMcjWoCJdUyRhBIzhBS1RoptBw1r5nHVVRTgejVA74K5yU5BfaceYBu0MRhQA6ILYqAU7bv-LQq-LpyICu8oYe45pB5Nle2u5WhecSvLprQSQ=='\n",
            "  )\n",
            "), GroundingChunk(\n",
            "  web=GroundingChunkWeb(\n",
            "    domain='kvue.com',\n",
            "    title='kvue.com',\n",
            "    uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcnjAn4_-cTQPuFTa-cs0tYIbrJLNNN9A9KzLV7YyvOY6RInmADX1R3eu8wNknVRFAcER5EcVDF82Db6FZu1gC57Vao_9AwSJDMpDLL6r50aHEV7x8cfDe'\n",
            "  )\n",
            ")] grounding_supports=[GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=102,\n",
            "    text='As of the morning of August 24, 2025, the temperature in Austin, Texas is approximately 74°F (23°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    1,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=193,\n",
            "    start_index=103,\n",
            "    text='However, different sources report slightly different readings, with some as high as 93°F.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=262,\n",
            "    start_index=194,\n",
            "    text='The \"feels like\" temperature is reported to be around 78°F (25°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=364,\n",
            "    start_index=264,\n",
            "    text='The forecast for the rest of the day indicates it will be sunny with a high of around 95°F (35°C).'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    0,\n",
            "    2,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=411,\n",
            "    start_index=365,\n",
            "    text='The chance of rain is very low, at about 0-3%.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    2,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=474,\n",
            "    start_index=412,\n",
            "    text='The wind is expected to be from the northeast at around 6 mph.'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=547,\n",
            "    start_index=476,\n",
            "    text=\"\"\"Here is the hourly forecast for the next few hours:\n",
            "*   **8 AM:** 75°F\"\"\"\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=567,\n",
            "    start_index=548,\n",
            "    text='*   **9 AM:** 80°F'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=588,\n",
            "    start_index=568,\n",
            "    text='*   **10 AM:** 84°F'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=609,\n",
            "    start_index=589,\n",
            "    text='*   **11 AM:** 88°F'\n",
            "  )\n",
            "), GroundingSupport(\n",
            "  grounding_chunk_indices=[\n",
            "    3,\n",
            "  ],\n",
            "  segment=Segment(\n",
            "    end_index=630,\n",
            "    start_index=610,\n",
            "    text='*   **12 PM:** 91°F'\n",
            "  )\n",
            ")] retrieval_metadata=RetrievalMetadata() retrieval_queries=None search_entry_point=SearchEntryPoint(\n",
            "  rendered_content=\"\"\"<style>\n",
            ".container {\n",
            "  align-items: center;\n",
            "  border-radius: 8px;\n",
            "  display: flex;\n",
            "  font-family: Google Sans, Roboto, sans-serif;\n",
            "  font-size: 14px;\n",
            "  line-height: 20px;\n",
            "  padding: 8px 12px;\n",
            "}\n",
            ".chip {\n",
            "  display: inline-block;\n",
            "  border: solid 1px;\n",
            "  border-radius: 16px;\n",
            "  min-width: 14px;\n",
            "  padding: 5px 16px;\n",
            "  text-align: center;\n",
            "  user-select: none;\n",
            "  margin: 0 8px;\n",
            "  -webkit-tap-highlight-color: transparent;\n",
            "}\n",
            ".carousel {\n",
            "  overflow: auto;\n",
            "  scrollbar-width: none;\n",
            "  white-space: nowrap;\n",
            "  margin-right: -12px;\n",
            "}\n",
            ".headline {\n",
            "  display: flex;\n",
            "  margin-right: 4px;\n",
            "}\n",
            ".gradient-container {\n",
            "  position: relative;\n",
            "}\n",
            ".gradient {\n",
            "  position: absolute;\n",
            "  transform: translate(3px, -9px);\n",
            "  height: 36px;\n",
            "  width: 9px;\n",
            "}\n",
            "@media (prefers-color-scheme: light) {\n",
            "  .container {\n",
            "    background-color: #fafafa;\n",
            "    box-shadow: 0 0 0 1px #0000000f;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #1f1f1f;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #ffffff;\n",
            "    border-color: #d2d2d2;\n",
            "    color: #5e5e5e;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #f2f2f2;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #d8d8d8;\n",
            "    border-color: #b6b6b6;\n",
            "  }\n",
            "  .logo-dark {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
            "  }\n",
            "}\n",
            "@media (prefers-color-scheme: dark) {\n",
            "  .container {\n",
            "    background-color: #1f1f1f;\n",
            "    box-shadow: 0 0 0 1px #ffffff26;\n",
            "  }\n",
            "  .headline-label {\n",
            "    color: #fff;\n",
            "  }\n",
            "  .chip {\n",
            "    background-color: #2c2c2c;\n",
            "    border-color: #3c4043;\n",
            "    color: #fff;\n",
            "    text-decoration: none;\n",
            "  }\n",
            "  .chip:hover {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:focus {\n",
            "    background-color: #353536;\n",
            "  }\n",
            "  .chip:active {\n",
            "    background-color: #464849;\n",
            "    border-color: #53575b;\n",
            "  }\n",
            "  .logo-light {\n",
            "    display: none;\n",
            "  }\n",
            "  .gradient {\n",
            "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
            "  }\n",
            "}\n",
            "</style>\n",
            "<div class=\"container\">\n",
            "  <div class=\"headline\">\n",
            "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
            "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
            "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
            "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
            "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
            "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
            "    </svg>\n",
            "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
            "  </div>\n",
            "  <div class=\"carousel\">\n",
            "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHI8wbgbks24t2blZt9g_vnSG2ZHh8od3_wGZW3zAADrIFxR3v2FQT--JMl76U5oB0K0NQFPBUPX7n85e1faC_kQGT9MV_MnLNPIm2uxYDLyOEv4Qgt4Lm9Eivr2lHQssS6zkfF3jIFYrZs4W7TB1c7sdMN4P7UFRz5m8uY8kMXwFAa5lc2-NTHRCpCpzrTDmOHoSyp5XpdA6Fs2WKnBMawtJgaJw==\">current temperature in Austin, TX</a>\n",
            "  </div>\n",
            "</div>\n",
            "\"\"\"\n",
            ") web_search_queries=['current temperature in Austin, TX']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHI8wbgbks24t2blZt9g_vnSG2ZHh8od3_wGZW3zAADrIFxR3v2FQT--JMl76U5oB0K0NQFPBUPX7n85e1faC_kQGT9MV_MnLNPIm2uxYDLyOEv4Qgt4Lm9Eivr2lHQssS6zkfF3jIFYrZs4W7TB1c7sdMN4P7UFRz5m8uY8kMXwFAa5lc2-NTHRCpCpzrTDmOHoSyp5XpdA6Fs2WKnBMawtJgaJw==\">current temperature in Austin, TX</a>\n",
              "  </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the current temperature in Austin, TX?\",\n",
        "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
        "\n",
        "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
        "\n",
        "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "For more examples of Function calling with Gemini, check out this notebook: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRR8HZhLlR-E",
        "outputId": "6e6dadc0-461d-4645-9656-756611597c77"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The weather in San Francisco is foggy.\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather like in San Francisco?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BDQPwgcxRN3",
        "outputId": "f87fa083-efcf-42b7-8aa6-7f7870c955cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id=None args={'destination': 'Paris'} name='get_destination'\n"
          ]
        }
      ],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
        "\n",
        "The Gemini API provides code execution as a tool, similar to function calling.\n",
        "After you add code execution as a tool, the model decides when to use it.\n",
        "\n",
        "For more examples of Code Execution, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W-3c7sy0nyz",
        "outputId": "6b6e4fdf-6cf9-47cc-ea43-b88ba04395ac"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "## Code\n",
              "\n",
              "```py\n",
              "def fibonacci(n):\n",
              "    if n <= 0:\n",
              "        return 0\n",
              "    elif n == 1:\n",
              "        return 1\n",
              "    else:\n",
              "        a, b = 0, 1\n",
              "        for _ in range(2, n + 1):\n",
              "            a, b = b, a + b\n",
              "        return b\n",
              "\n",
              "fib_20 = fibonacci(20)\n",
              "print(f'The 20th Fibonacci number is: {fib_20}')\n",
              "```\n",
              "\n",
              "### Output\n",
              "\n",
              "```\n",
              "The 20th Fibonacci number is: 6765\n",
              "\n",
              "```\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b5adb2eb70"
      },
      "source": [
        "## Thinking mode examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "### **Example 1**: Code generation\n",
        "\n",
        "Gemini 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing.\n",
        "\n",
        "Let's see how the model uses its reasoning capabilities to create a video game, using executable code from a single line prompt. See the example game [here](https://www.youtube.com/watch?v=RLCBSpgos6s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f120dff0d16",
        "outputId": "1d709def-0163-4462-beac-f16e78052f51"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Of course! Here is a complete, self-contained p5.js endless runner game featuring a pixelated dinosaur, a parallax scrolling background, and on-screen instructions.\n",
              "\n",
              "Just copy and paste this entire code into a p5.js editor (like the [p5.js Web Editor](https://editor.p5js.org/)) and press play.\n",
              "\n",
              "### Game Features:\n",
              "*   **Pixel Art Dino:** A running dinosaur drawn with simple rectangles.\n",
              "*   **Endless Scrolling:** The world moves towards you.\n",
              "*   **Parallax Background:** Multiple layers of mountains and a starry sky move at different speeds, creating a sense of depth.\n",
              "*   **Increasing Difficulty:** The game gets faster and obstacles appear more frequently over time.\n",
              "*   **On-Screen Instructions:** All controls and game state information are displayed directly in the scene.\n",
              "*   **Simple Controls:** Just one button to jump!\n",
              "\n",
              "---\n",
              "\n",
              "### `sketch.js`\n",
              "\n",
              "```javascript\n",
              "//\n",
              "// --- PIXEL DINO RUN ---\n",
              "// A captivating endless runner game in p5.js\n",
              "//\n",
              "\n",
              "// --- Game State ---\n",
              "let gameState = 'start'; // 'start', 'playing', 'gameOver'\n",
              "\n",
              "// --- Player (Dino) ---\n",
              "let dino;\n",
              "let gravity = 0.6;\n",
              "let jumpPower = -15;\n",
              "\n",
              "// --- World ---\n",
              "let groundY;\n",
              "let gameSpeed = 6;\n",
              "let minGameSpeed = 6;\n",
              "let maxGameSpeed = 15;\n",
              "\n",
              "// --- Obstacles ---\n",
              "let obstacles = [];\n",
              "let obstacleSpawnFrame;\n",
              "let initialSpawnRate = 90; // Spawn every 1.5 seconds at 60fps\n",
              "let currentSpawnRate;\n",
              "\n",
              "// --- Scoring ---\n",
              "let score = 0;\n",
              "\n",
              "// --- Background Elements ---\n",
              "let stars = [];\n",
              "let farMountains = [];\n",
              "let nearMountains = [];\n",
              "\n",
              "// =================================================================\n",
              "//  SETUP: Runs once at the beginning\n",
              "// =================================================================\n",
              "function setup() {\n",
              "  createCanvas(windowWidth, windowHeight);\n",
              "  rectMode(CENTER);\n",
              "  textAlign(CENTER, CENTER);\n",
              "  noStroke();\n",
              "\n",
              "  // Set ground level\n",
              "  groundY = height * 0.8;\n",
              "\n",
              "  // Initialize background elements\n",
              "  for (let i = 0; i < 100; i++) {\n",
              "    stars.push({\n",
              "      x: random(width),\n",
              "      y: random(height * 0.7),\n",
              "      size: random(1, 3)\n",
              "    });\n",
              "  }\n",
              "  for (let i = 0; i < 15; i++) {\n",
              "    farMountains.push({\n",
              "      x: random(width * 1.5),\n",
              "      y: groundY,\n",
              "      w: random(200, 400),\n",
              "      h: random(100, 250)\n",
              "    });\n",
              "  }\n",
              "  for (let i = 0; i < 10; i++) {\n",
              "    nearMountains.push({\n",
              "      x: random(width * 1.5),\n",
              "      y: groundY,\n",
              "      w: random(300, 500),\n",
              "      h: random(150, 300)\n",
              "    });\n",
              "  }\n",
              "\n",
              "  resetGame();\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  DRAW: Runs continuously in a loop\n",
              "// =================================================================\n",
              "function draw() {\n",
              "  // Manage game states\n",
              "  if (gameState === 'start') {\n",
              "    drawStartScreen();\n",
              "  } else if (gameState === 'playing') {\n",
              "    runGame();\n",
              "  } else if (gameState === 'gameOver') {\n",
              "    drawGameOverScreen();\n",
              "  }\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  GAME LOGIC & RENDERING\n",
              "// =================================================================\n",
              "\n",
              "function runGame() {\n",
              "  // --- Background ---\n",
              "  drawBackground();\n",
              "\n",
              "  // --- Dino Logic ---\n",
              "  dino.vy += gravity;\n",
              "  dino.y += dino.vy;\n",
              "\n",
              "  // Prevent dino from falling through the ground\n",
              "  if (dino.y > groundY - dino.h / 2) {\n",
              "    dino.y = groundY - dino.h / 2;\n",
              "    dino.vy = 0;\n",
              "    dino.isJumping = false;\n",
              "  }\n",
              "\n",
              "  // --- Obstacles Logic ---\n",
              "  manageObstacles();\n",
              "\n",
              "  // --- Drawing ---\n",
              "  drawDino();\n",
              "  drawObstacles();\n",
              "\n",
              "  // --- Scoring & Difficulty ---\n",
              "  score++;\n",
              "  if (gameSpeed < maxGameSpeed) {\n",
              "    gameSpeed += 0.003; // Slowly increase speed\n",
              "  }\n",
              "  if (currentSpawnRate > 40) {\n",
              "    currentSpawnRate -= 0.05; // Slowly decrease time between spawns\n",
              "  }\n",
              "  \n",
              "  // --- UI ---\n",
              "  drawUI();\n",
              "}\n",
              "\n",
              "function manageObstacles() {\n",
              "  // Spawn new obstacles\n",
              "  if (frameCount > obstacleSpawnFrame) {\n",
              "    let obstacleType = random() > 0.3 ? 'cactus_single' : 'cactus_double';\n",
              "    obstacles.push(new Obstacle(obstacleType));\n",
              "    obstacleSpawnFrame = frameCount + int(random(currentSpawnRate * 0.8, currentSpawnRate * 1.2));\n",
              "  }\n",
              "\n",
              "  // Update and check obstacles\n",
              "  for (let i = obstacles.length - 1; i >= 0; i--) {\n",
              "    obstacles[i].update();\n",
              "\n",
              "    if (obstacles[i].isOffscreen()) {\n",
              "      obstacles.splice(i, 1);\n",
              "    } else if (obstacles[i].collidesWith(dino)) {\n",
              "      gameState = 'gameOver';\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  DRAWING FUNCTIONS\n",
              "// =================================================================\n",
              "\n",
              "function drawBackground() {\n",
              "  // Sky Gradient\n",
              "  let skyTop = color(10, 20, 40);\n",
              "  let skyBottom = color(60, 80, 120);\n",
              "  for (let y = 0; y < height; y++) {\n",
              "    let inter = map(y, 0, height * 0.8, 0, 1);\n",
              "    let c = lerpColor(skyTop, skyBottom, inter);\n",
              "    stroke(c);\n",
              "    line(0, y, width, y);\n",
              "  }\n",
              "  noStroke();\n",
              "\n",
              "  // Stars\n",
              "  fill(255, 255, 200, 200);\n",
              "  for (const star of stars) {\n",
              "    ellipse(star.x, star.y, star.size);\n",
              "    star.x -= gameSpeed * 0.1;\n",
              "    if (star.x < 0) star.x = width;\n",
              "  }\n",
              "\n",
              "  // Far Mountains (Parallax Layer 1)\n",
              "  fill(40, 50, 70);\n",
              "  for (const m of farMountains) {\n",
              "    rect(m.x, m.y - m.h / 2, m.w, m.h);\n",
              "    m.x -= gameSpeed * 0.25;\n",
              "    if (m.x + m.w / 2 < 0) m.x = width + m.w / 2 + random(50, 150);\n",
              "  }\n",
              "\n",
              "  // Near Mountains (Parallax Layer 2)\n",
              "  fill(60, 70, 90);\n",
              "  for (const m of nearMountains) {\n",
              "    rect(m.x, m.y - m.h / 2, m.w, m.h);\n",
              "    m.x -= gameSpeed * 0.5;\n",
              "    if (m.x + m.w / 2 < 0) m.x = width + m.w / 2 + random(50, 200);\n",
              "  }\n",
              "\n",
              "  // Ground\n",
              "  fill(100, 80, 60);\n",
              "  rect(width / 2, groundY + (height - groundY) / 2, width, height - groundY);\n",
              "}\n",
              "\n",
              "function drawDino() {\n",
              "  push();\n",
              "  translate(dino.x, dino.y);\n",
              "  fill(80, 180, 80); // Dino Green\n",
              "\n",
              "  // Body\n",
              "  rect(0, 0, 40, 50);\n",
              "  // Head\n",
              "  rect(15, -20, 30, 20);\n",
              "  // Tail\n",
              "  triangle(-20, 10, -40, -10, -20, -10);\n",
              "\n",
              "  // Legs (simple animation)\n",
              "  let legY = 25;\n",
              "  let legX1 = -5;\n",
              "  let legX2 = 15;\n",
              "  let legW = 10;\n",
              "  let legH = 20;\n",
              "\n",
              "  if (dino.isJumping) {\n",
              "    // Both legs drawn back when jumping\n",
              "    rect(legX1, legY + 5, legW, legH);\n",
              "    rect(legX2, legY + 5, legW, legH);\n",
              "  } else {\n",
              "    // Running animation\n",
              "    let cycle = floor(frameCount / 8) % 2;\n",
              "    if (cycle === 0) {\n",
              "      rect(legX1, legY, legW, legH); // Back leg\n",
              "      rect(legX2, legY + 5, legW, legH); // Front leg\n",
              "    } else {\n",
              "      rect(legX1, legY + 5, legW, legH); // Back leg\n",
              "      rect(legX2, legY, legW, legH); // Front leg\n",
              "    }\n",
              "  }\n",
              "\n",
              "  // Eye\n",
              "  fill(0);\n",
              "  ellipse(22, -22, 5, 5);\n",
              "\n",
              "  pop();\n",
              "}\n",
              "\n",
              "function drawObstacles() {\n",
              "  for (const obs of obstacles) {\n",
              "    obs.draw();\n",
              "  }\n",
              "}\n",
              "\n",
              "function drawUI() {\n",
              "  fill(255);\n",
              "  textSize(32);\n",
              "  textFont('monospace');\n",
              "  textAlign(RIGHT, TOP);\n",
              "  text(`SCORE: ${floor(score)}`, width - 20, 20);\n",
              "  textAlign(CENTER, CENTER); // Reset alignment\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  GAME STATE SCREENS\n",
              "// =================================================================\n",
              "\n",
              "function drawStartScreen() {\n",
              "  drawBackground();\n",
              "  drawDino();\n",
              "  \n",
              "  fill(0, 0, 0, 150);\n",
              "  rect(width / 2, height / 2, width, height);\n",
              "\n",
              "  fill(255);\n",
              "  textSize(64);\n",
              "  textFont('monospace');\n",
              "  text('PIXEL DINO RUN', width / 2, height / 3);\n",
              "\n",
              "  textSize(32);\n",
              "  text('Press [SPACE] to Jump', width / 2, height / 2);\n",
              "  text('Press any key to Start', width / 2, height / 2 + 50);\n",
              "}\n",
              "\n",
              "function drawGameOverScreen() {\n",
              "  // Keep drawing the game state as it was when the game ended\n",
              "  drawBackground();\n",
              "  drawDino();\n",
              "  drawObstacles();\n",
              "\n",
              "  // Dark overlay\n",
              "  fill(0, 0, 0, 180);\n",
              "  rect(width / 2, height / 2, width, height);\n",
              "\n",
              "  // Game Over text\n",
              "  fill(255, 80, 80);\n",
              "  textSize(80);\n",
              "  textFont('monospace');\n",
              "  text('GAME OVER', width / 2, height / 3);\n",
              "\n",
              "  fill(255);\n",
              "  textSize(40);\n",
              "  text(`Final Score: ${floor(score)}`, width / 2, height / 2);\n",
              "\n",
              "  textSize(28);\n",
              "  text(\"Press 'R' to Restart\", width / 2, height / 2 + 60);\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  PLAYER INPUT\n",
              "// =================================================================\n",
              "\n",
              "function keyPressed() {\n",
              "  if (gameState === 'playing') {\n",
              "    if ((key === ' ' || keyCode === UP_ARROW) && !dino.isJumping) {\n",
              "      dino.isJumping = true;\n",
              "      dino.vy = jumpPower;\n",
              "    }\n",
              "  } else if (gameState === 'gameOver') {\n",
              "    if (key === 'r' || key === 'R') {\n",
              "      resetGame();\n",
              "      gameState = 'playing';\n",
              "    }\n",
              "  } else if (gameState === 'start') {\n",
              "    gameState = 'playing';\n",
              "  }\n",
              "}\n",
              "\n",
              "\n",
              "// =================================================================\n",
              "//  UTILITY & RESET\n",
              "// =================================================================\n",
              "\n",
              "function resetGame() {\n",
              "  // Reset Dino\n",
              "  dino = {\n",
              "    x: width / 4,\n",
              "    y: groundY - 25,\n",
              "    w: 40,\n",
              "    h: 50,\n",
              "    vy: 0,\n",
              "    isJumping: false\n",
              "  };\n",
              "\n",
              "  // Reset obstacles\n",
              "  obstacles = [];\n",
              "  obstacleSpawnFrame = frameCount + initialSpawnRate;\n",
              "  currentSpawnRate = initialSpawnRate;\n",
              "\n",
              "  // Reset score and speed\n",
              "  score = 0;\n",
              "  gameSpeed = minGameSpeed;\n",
              "}\n",
              "\n",
              "// Handle window resizing\n",
              "function windowResized() {\n",
              "    resizeCanvas(windowWidth, windowHeight);\n",
              "    groundY = height * 0.8;\n",
              "    resetGame();\n",
              "    gameState = 'start';\n",
              "}\n",
              "\n",
              "// =================================================================\n",
              "//  OBSTACLE CLASS\n",
              "// =================================================================\n",
              "class Obstacle {\n",
              "  constructor(type) {\n",
              "    this.x = width;\n",
              "    this.type = type;\n",
              "\n",
              "    if (type === 'cactus_single') {\n",
              "      this.w = 20;\n",
              "      this.h = 50;\n",
              "    } else if (type === 'cactus_double') {\n",
              "      this.w = 45;\n",
              "      this.h = 50;\n",
              "    }\n",
              "\n",
              "    this.y = groundY - this.h / 2;\n",
              "  }\n",
              "\n",
              "  update() {\n",
              "    this.x -= gameSpeed;\n",
              "  }\n",
              "\n",
              "  isOffscreen() {\n",
              "    return this.x < -this.w;\n",
              "  }\n",
              "\n",
              "  draw() {\n",
              "    push();\n",
              "    fill(100, 150, 100); // Cactus green\n",
              "    if (this.type === 'cactus_single') {\n",
              "      rect(this.x, this.y, this.w, this.h);\n",
              "    } else if (this.type === 'cactus_double') {\n",
              "      rect(this.x - 12.5, this.y, 20, this.h); // Left cactus\n",
              "      rect(this.x + 12.5, this.y - 10, 20, this.h - 20); // Right cactus\n",
              "    }\n",
              "    pop();\n",
              "  }\n",
              "\n",
              "  collidesWith(player) {\n",
              "    // Simple Axis-Aligned Bounding Box collision detection\n",
              "    // Get hitboxes for player and obstacle\n",
              "    let dinoBox = {\n",
              "      left: player.x - player.w / 2,\n",
              "      right: player.x + player.w / 2,\n",
              "      top: player.y - player.h / 2,\n",
              "      bottom: player.y + player.h / 2,\n",
              "    };\n",
              "\n",
              "    let obsBox = {\n",
              "      left: this.x - this.w / 2,\n",
              "      right: this.x + this.w / 2,\n",
              "      top: this.y - this.h / 2,\n",
              "      bottom: this.y + this.h / 2,\n",
              "    };\n",
              "    \n",
              "    // Add a little padding to make collision feel more fair\n",
              "    dinoBox.left += 5;\n",
              "    dinoBox.right -= 5;\n",
              "    \n",
              "    return (\n",
              "      dinoBox.right > obsBox.left &&\n",
              "      dinoBox.left < obsBox.right &&\n",
              "      dinoBox.bottom > obsBox.top &&\n",
              "      dinoBox.top < obsBox.bottom\n",
              "    );\n",
              "  }\n",
              "}\n",
              "```"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "  Make me a captivating endless runner game. Key instructions on the screen. p5js scene, no HTML.\n",
        "  I like pixelated dinosaurs and interesting backgrounds.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecf22b47bdc3"
      },
      "source": [
        "### **Example 2**: Multimodal reasoning (Geometry)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using multimodal capabilities to reason across text and image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60260c0ac118",
        "outputId": "8861d3d2-f165-4b7b-8300-c9c3554babfc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_file_url = (\n",
        "    \"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\"\n",
        ")\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c972334f62ff",
        "outputId": "9fef8da0-3bba-47c9-aa56-c7fed2f35ac7"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the image, we can determine the area of the overlapping region by following these steps:\n",
              "\n",
              "1.  **Identify the shapes:** We have a circle and a right-angled triangle.\n",
              "\n",
              "2.  **Find the properties of the circle:** The lines from the center to the edge of the circle (the radii) are all labeled with the number 3. Therefore, the radius (**r**) of the circle is **3**.\n",
              "\n",
              "3.  **Analyze the overlap:** The right-angle vertex of the triangle is located at the exact center of the circle. This means the overlapping area is a sector of the circle.\n",
              "\n",
              "4.  **Determine the angle of the sector:** The angle of this sector is the same as the angle of the triangle's corner that is at the circle's center, which is a right angle. A right angle is **90°**.\n",
              "\n",
              "5.  **Calculate the area of the sector:** The area of a circle is given by the formula A = πr². The area of a sector is a fraction of the total circle's area, determined by its angle.\n",
              "\n",
              "   *   Area of the full circle = π * (3)² = 9π\n",
              "   *   The fraction of the circle that the sector represents is 90° / 360° = 1/4.\n",
              "\n",
              "   So, the area of the overlapping region is 1/4 of the total area of the circle.\n",
              "\n",
              "   Area of overlap = (1/4) * 9π = **9π / 4**\n",
              "\n",
              "As a decimal, this is approximately 7.07 square units."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52656e92cd69"
      },
      "source": [
        "### **Example 3**:  Math and problem solving\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d46387bdc9e6",
        "outputId": "0e3aa3ad-bd85-49bb-973e-3dfcaf417438"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/pool.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_file_url = \"https://storage.googleapis.com/generativeai-downloads/images/pool.png\"\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46b694793eb0",
        "outputId": "8843781b-72ba-4955-ccb2-e017aabecc27"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "This is a classic riddle! Here's how you solve it:\n",
              "\n",
              "You need to turn the **9** ball upside down to make it a **6**.\n",
              "\n",
              "Then, you can add the numbers on these three balls:\n",
              "\n",
              "**11 + 13 + 6 = 30**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hIJVEr0RQY8S",
        "rZV2TY5Pa3Dd",
        "hYKAzG1sH-K1",
        "mSUWWlrrlR-D",
        "h4syyLEClGcn"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m131",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}